{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4d981-14ea-47de-9bb7-ba7771fbe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "tfk = tf.keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b7fe4-9548-4aa0-b957-c369b5d9bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func must be function that takes in model, ion, and conc as parameters in this order\n",
    "def apply_to_dict(func):\n",
    "    return {model: {ion: {conc: func(model, ion, conc)\n",
    "                           for conc in CONCS} \n",
    "                     for ion in IONS}\n",
    "             for model in MODEL_N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f193ce-417b-4bf0-907c-2ed7842d9f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3119973509999996\n"
     ]
    }
   ],
   "source": [
    "from time import process_time\n",
    "MODEL_N = [i for i in range(1, 2)]\n",
    "IONS = [\"Na+\", \"MG\"]\n",
    "CONCS = [c for c in range(10, 60, 10)]\n",
    "TIME_FRAMES = [t for t in range(101)]\n",
    "datafiles = apply_to_dict(lambda m, i, c: f\"../data/distance_npz/filtered_sasdfb9_m{m}_{c}_{i}.npz\")\n",
    "t1 = process_time()\n",
    "npz_dict = apply_to_dict(lambda m, i, c: np.load(datafiles[m][i][c])[\"arr_0\"])\n",
    "t2 = process_time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5867baca-80d7-4c8f-a665-7e409bbd10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_tuple = [(m,i,c,t) for m in MODEL_N for i in IONS for c in CONCS for t in TIME_FRAMES]\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(spec_tuple)\n",
    "# construct dataset with label shuffled\n",
    "label = np.array([str(m)+\"_\"+str(c)+\"_\"+i+\"_\"+str(t) for m,i,c,t in spec_tuple])\n",
    "data = np.stack([npz_dict[m][i][c][t] for m, i, c, t in spec_tuple])\n",
    "# split set into train and test\n",
    "n_set = len(label)\n",
    "# split train and test dataset to be 90% and 10% of the entire dataset\n",
    "split_idx = math.ceil(n_set * 0.9)\n",
    "# construct train dataset\n",
    "train_feature_dataset = tf.data.Dataset.from_tensor_slices(data[:split_idx])\n",
    "train_label_dataset = tf.data.Dataset.from_tensor_slices(label[:split_idx])\n",
    "train_dataset = tf.data.Dataset.zip((train_feature_dataset, train_label_dataset))\n",
    "# construct test dataset\n",
    "test_feature_dataset = tf.data.Dataset.from_tensor_slices(data[split_idx:])\n",
    "test_label_dataset = tf.data.Dataset.from_tensor_slices(label[split_idx:])\n",
    "test_dataset = tf.data.Dataset.zip((test_feature_dataset, test_label_dataset))\n",
    "# save dataset\n",
    "train_dataset.save(\"../dataset/m1_ssRNA_train_distributed100atoms_dataset\")\n",
    "test_dataset.save(\"../dataset/m1_ssRNA_test_distributed100atoms_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f558742e-bd22-48f5-8e49-433b24b4de56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36marray_split\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;31m# handle array case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mNsections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_or_sections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0mdiv_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_or_sections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNtotal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-60c30f178d11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_atom_idx_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom_idx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreprocess_atom_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_idx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_atom_idx_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-60c30f178d11>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_atom_idx_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom_idx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreprocess_atom_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_idx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_atom_idx_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f4139e08ed1d>\u001b[0m in \u001b[0;36mpreprocess_atom_set\u001b[0;34m(rna, atom_idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mpair_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_meshgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_meshgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# TODO can be optimized to only calculate distance once for each pair but the computation quick so I am skipping for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mpair_distance_array_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_and_pack_distance_in_array_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     formatted_pair_distance_array_frames = np.array(\n\u001b[1;32m     47\u001b[0m         [trunc_or_pad_distance_array(frame, maxlen = 100) \n",
      "\u001b[0;32m<ipython-input-27-f4139e08ed1d>\u001b[0m in \u001b[0;36mcompute_and_pack_distance_in_array_frames\u001b[0;34m(rna, pair_grid)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# (number of frames, number of columns, number of rows)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maxes_ordered_distances_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances_by_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     packed_distances_frames = np.apply_along_axis(\n\u001b[0m\u001b[1;32m      9\u001b[0m         lambda arr: np.array_split(arr, len(arr)), 2, axes_ordered_distances_frames)\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_distances_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f4139e08ed1d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maxes_ordered_distances_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances_by_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     packed_distances_frames = np.apply_along_axis(\n\u001b[0;32m----> 9\u001b[0;31m         lambda arr: np.array_split(arr, len(arr)), 2, axes_ordered_distances_frames)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_distances_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36marray_split\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36marray_split\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    781\u001b[0m                          \u001b[0mextras\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNeach_section\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                          (Nsections-extras) * [Neach_section])\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0mdiv_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0msub_arys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_atom_idx_set = len(atom_idx_list)\n",
    "dataset_array = np.concatenate([preprocess_atom_set(rna, atom_idx_list[i]) for i in tqdm(range(n_atom_idx_set))])\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(dataset_array)\n",
    "n_set = len(dataset_array)\n",
    "split_idx = math.ceil(n_set/2)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(dataset_array[:split_idx])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(dataset_array[split_idx:])\n",
    "train_dataset.save(\"VAE/dataset/ssRNA_train_dataset\")\n",
    "test_dataset.save(\"VAE/dataset/ssRNA_test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d708c47-4550-4c7b-b76e-ea4e64f44112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING SECCTION\n",
    "atom_idx = atom_idx_list[0]\n",
    "pair_meshgrid = np.meshgrid(atom_idx, np.transpose(atom_idx))\n",
    "pair_grid = np.dstack((pair_meshgrid[0], pair_meshgrid[1]))\n",
    "pair_distance_array_frames = compute_and_pack_distance_in_array_frames(rna, pair_grid)\n",
    "formatted_pair_distance_array_frames = np.array(\n",
    "    [trunc_or_pad_distance_array(frame, maxlen = 100) \n",
    "     for frame in pair_distance_array_frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b4ae9-7fc7-4d6a-8205-d216113fcae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # LEGACY CODE, now the gro files are filtered in the MD_sim pipeline so no need to select residues\n",
    "# t = md.load('VAE/md_0_1.gro')\n",
    "# rna_idx = t.top.select('resi < 30')\n",
    "# rna = t.atom_slice(rna_idx)\n",
    "def compute_and_pack_distance_in_array_frames(rna, pair_grid):\n",
    "    # in distances_frames, the axes were (number of columns, number of frames, number of rows)\n",
    "    # where number of columns and rows are both equal to the number of atoms\n",
    "    distances_by_columns = np.array([md.compute_distances(rna, column) for column in pair_grid])\n",
    "    # in axes_ordered_distances_frames, the axes are \n",
    "    # (number of frames, number of columns, number of rows)\n",
    "    axes_ordered_distances_frames = distances_by_columns.transpose(1,0,2)\n",
    "    packed_distances_frames = np.apply_along_axis(\n",
    "        lambda arr: np.array_split(arr, len(arr)), 2, axes_ordered_distances_frames)\n",
    "    return(packed_distances_frames)\n",
    "\n",
    "# Given an 3D array (n_atom x n_atom x 1), n_atom is the number of atom in one batch of residue and \n",
    "# may vary depending on the number of atoms in each residue; return a 100x100x1 array either by \n",
    "# truncating or padding the given array\n",
    "def trunc_or_pad_distance_array(distance_array, maxlen=100):\n",
    "    if distance_array.shape[0] != distance_array.shape[1]:\n",
    "        raise Exception(\"the first and second dimension of the given distance array does not match\")\n",
    "    n_atom = distance_array.shape[0]\n",
    "    if n_atom < maxlen:\n",
    "        pad_n_pre = int((maxlen-n_atom)/2)\n",
    "        pad_n_post = (maxlen-n_atom)/2\n",
    "        if pad_n_pre != pad_n_post:\n",
    "            pad_n_post = math.ceil(pad_n_post)\n",
    "        distance_array = np.pad(\n",
    "            distance_array, \n",
    "            ((pad_n_pre, pad_n_post), \n",
    "             (pad_n_pre, pad_n_post),\n",
    "             (0, 0)))\n",
    "    elif n_atom > maxlen:\n",
    "        trunc_n_pre = int((n_atom-maxlen)/2)\n",
    "        trunc_n_post = (n_atom-maxlen)/2\n",
    "        if trunc_n_pre != trunc_n_post:\n",
    "            trunc_n_post = math.ceil(trunc_n_post)\n",
    "        end_idx = int(n_atom - trunc_n_post)\n",
    "        # truncate first dimension\n",
    "        distance_array = distance_array[trunc_n_pre:end_idx]\n",
    "        # truncate second dimension\n",
    "        distance_array = np.array([col[trunc_n_pre:end_idx] for col in distance_array])    \n",
    "    return distance_array\n",
    "\n",
    "def preprocess_atom_set(rna, atom_idx):\n",
    "    pair_meshgrid = np.meshgrid(atom_idx, np.transpose(atom_idx))\n",
    "    pair_grid = np.dstack((pair_meshgrid[0], pair_meshgrid[1]))\n",
    "    # TODO can be optimized to only calculate distance once for each pair but the computation quick so I am skipping for now\n",
    "    pair_distance_array_frames = compute_and_pack_distance_in_array_frames(rna, pair_grid)\n",
    "    formatted_pair_distance_array_frames = np.array(\n",
    "        [trunc_or_pad_distance_array(frame, maxlen = 100) \n",
    "         for frame in pair_distance_array_frames])\n",
    "    return formatted_pair_distance_array_frames\n",
    "n_atom_idx_set = len(atom_idx_list)\n",
    "n_atom_idx_set = 2\n",
    "dataset_array = np.concatenate([preprocess_atom_set(rna, atom_idx_list[i]) for i in tqdm(range(n_atom_idx_set))])\n",
    "# from time import process_time\n",
    "# t1 = process_time()\n",
    "# tt = np.load(\"../data/distance_npy/filtered_sasdfb9_m1_20_MG.npz\")[\"arr_0\"]\n",
    "# t2 = process_time()\n",
    "# ttt = np.load(\"../data/distance_npy/filtered_sasdfb9_m1_20_MG.npy\")\n",
    "# t3 = process_time()\n",
    "# print(f\"{t2-t1}; {t3-t2}\")\n",
    "# n_residues_dict = rna.top.n_residues\n",
    "# batch_residue_idx = [(i, i+3) for i in range(0,n_residues,3)]\n",
    "# atom_idx_list = []\n",
    "# for batch_start, batch_end in batch_residue_idx:\n",
    "#     atom_idx_list.append(rna.top.select(f'resi >= {batch_start} and resi < {batch_end}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
